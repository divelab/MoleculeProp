{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from deeper_dagnn import DeeperDAGNN_node_Virtualnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygPCQM4MDataset()\n",
    "evaluator = PCQM4MEvaluator()\n",
    "split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id))\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=256, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 34093834\n"
     ]
    }
   ],
   "source": [
    "num_layers = 16\n",
    "emb_dim = 600\n",
    "drop_ratio = 0.25\n",
    "\n",
    "total_splits = 5\n",
    "runs_per_split = 4\n",
    "model_list = []\n",
    "for _ in range(total_splits):\n",
    "    model_list.append([DeeperDAGNN_node_Virtualnode(num_layers=num_layers, emb_dim=emb_dim, drop_ratio = drop_ratio).to(device) for _ in range(runs_per_split)])\n",
    "\n",
    "for split_id in range(1, total_splits + 1):\n",
    "    for run_id in range(1, runs_per_split + 1):\n",
    "        checkpoint_model = './2d_checkpoints/checkpoint_split{}_{}'.format(split_id, run_id)\n",
    "        checkpoint_path = os.path.join(checkpoint_model, 'checkpoint.pt')\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model_list[split_id - 1][run_id - 1].load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "num_params = sum(p.numel() for p in model_list[0][0].parameters())\n",
    "print(f'#Params: {num_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, valid_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    res_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 298/298 [00:29<00:00, 10.19it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.38it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.63it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.59it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:28<00:00, 10.35it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.59it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.26it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.53it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:28<00:00, 10.31it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.58it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.69it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.61it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:29<00:00, 10.10it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.63it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.53it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.66it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:28<00:00, 10.32it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.62it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.62it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.66it/s]\n"
     ]
    }
   ],
   "source": [
    "## get validation result for every run\n",
    "valid_pred_all = []\n",
    "y_true_list = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    valid_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        res_dict = eval(model_list[split_id][run_id], valid_loader)\n",
    "        valid_pred_split.append(res_dict[\"y_pred\"])\n",
    "        if run_id == 0:\n",
    "            y_true_list.append(res_dict[\"y_true\"])\n",
    "    valid_pred_all.append(valid_pred_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load validation result of conformer\n",
    "conformer_valid_pred_list = []\n",
    "for i in range(total_splits):\n",
    "    conformer_valid_pred_list.append(np.load('/mnt/dive/shared/xuan.zhang/kddcup21/code/test_result/submission/valid_{}/y_pred_pcqm4m_ens_{}.npz'.format(i+1, i+1)))\n",
    "\n",
    "## load validation result of yaochen  \n",
    "yaochen1 = torch.load('/mnt/dive/shared/yaochen.xie/kddcup_result/split3_pred.pt')\n",
    "yaochen2 = torch.load('/mnt/dive/shared/yaochen.xie/kddcup_result/split4_pred.pt')\n",
    "\n",
    "valid_pred_all[2][1] = torch.from_numpy(yaochen1)\n",
    "valid_pred_all[3][2] = torch.from_numpy(yaochen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on validation set: 0.11165887862443924\n",
      "MAE on validation set: 0.11134455353021622\n",
      "MAE on validation set: 0.112143874168396\n",
      "MAE on validation set: 0.11106374859809875\n",
      "MAE on validation set: 0.11137156933546066\n"
     ]
    }
   ],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_res_split = []\n",
    "for i in range(total_splits):\n",
    "    valid_pred = torch.mean(torch.stack(valid_pred_all[i]), axis=0)\n",
    "    valid_pred_final = (valid_pred.numpy() + w * conformer_valid_pred_list[i]['y_pred']) / (1 + w)\n",
    "    idx = (conformer_valid_pred_list[i]['y_pred'] == -1)\n",
    "    valid_pred_final[idx] = valid_pred[idx]\n",
    "    ensemble_res_split.append(valid_pred_final)\n",
    "\n",
    "for i in range(len(ensemble_res_split)):\n",
    "    input_dict = {\"y_true\": y_true_list[i].numpy(), \"y_pred\": ensemble_res_split[i]}\n",
    "    print('MAE on validation set:', evaluator.eval(input_dict)[\"mae\"])\n",
    "## ensemble over all splits\n",
    "# y_pred = np.mean(np.array(ensemble_res_split), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, test_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1475/1475 [02:27<00:00, 10.03it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:54<00:00, 12.89it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:54<00:00, 12.93it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 12.96it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:27<00:00, 10.01it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 12.94it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:55<00:00, 12.77it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 12.96it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:25<00:00, 10.11it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:55<00:00, 12.75it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:54<00:00, 12.92it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 13.03it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:27<00:00, 10.03it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:54<00:00, 12.91it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 13.00it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 12.98it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:27<00:00,  9.98it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:54<00:00, 12.93it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 12.95it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 13.04it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred_all = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    test_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        y_pred = test_eval(model_list[split_id][run_id], test_loader)\n",
    "        test_pred_split.append(y_pred)\n",
    "    test_pred_all.append(test_pred_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test result of conformer\n",
    "conformer_test_pred_list = []\n",
    "for i in range(total_splits):\n",
    "    conformer_test_pred_list.append(np.load('/mnt/dive/shared/xuan.zhang/kddcup21/code/test_result/submission/test_{}/y_pred_pcqm4m_ens_{}.npz'.format(i+1, i+1)))\n",
    "\n",
    "## load validation result of yaochen  \n",
    "yaochen1 = torch.load('/mnt/dive/shared/yaochen.xie/kddcup_result/split3_test_pred.pt')\n",
    "yaochen2 = torch.load('/mnt/dive/shared/yaochen.xie/kddcup_result/split4_test_pred.pt')\n",
    "\n",
    "test_pred_all[2][1] = torch.from_numpy(yaochen1)\n",
    "test_pred_all[3][2] = torch.from_numpy(yaochen2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_test_res_split = []\n",
    "for i in range(total_splits):\n",
    "    test_pred = torch.mean(torch.stack(test_pred_all[i]), axis=0)\n",
    "    test_pred_final = (test_pred.numpy() + w * conformer_test_pred_list[i]['y_pred']) / (1 + w)\n",
    "    idx = (conformer_test_pred_list[i]['y_pred'] == -1)\n",
    "    test_pred_final[idx] = test_pred[idx]\n",
    "    ensemble_test_res_split.append(test_pred_final)\n",
    " \n",
    "## ensemble over all splits\n",
    "save_test_dir = './test_result'\n",
    "y_pred = np.mean(np.array(ensemble_test_res_split), axis=0)\n",
    "evaluator.save_test_submission({'y_pred': y_pred}, save_test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd",
   "language": "python",
   "name": "kdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
