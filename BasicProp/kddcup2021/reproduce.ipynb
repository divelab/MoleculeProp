{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef3bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from deeper_dagnn import DeeperDAGNN_node_Virtualnode\n",
    "from conformer.dataset import ConfLmdbDataset, ConfDataLoader\n",
    "from conformer.confnet_dss import ConfNetDSS\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8110a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe73805",
   "metadata": {},
   "source": [
    "## Validation and Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35df3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, valid_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    res_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "def test_eval(model, test_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb3037",
   "metadata": {},
   "source": [
    "## 2D Model Validation / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935cd4cb",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991de6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygPCQM4MDataset()\n",
    "evaluator = PCQM4MEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307d8c7",
   "metadata": {},
   "source": [
    "### Define and Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602581c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 34093834\n"
     ]
    }
   ],
   "source": [
    "num_layers = 16\n",
    "emb_dim = 600\n",
    "drop_ratio = 0.25\n",
    "\n",
    "total_splits = 5\n",
    "runs_per_split = 4\n",
    "model_list = []\n",
    "for _ in range(total_splits):\n",
    "    model_list.append([DeeperDAGNN_node_Virtualnode(num_layers=num_layers, emb_dim=emb_dim, drop_ratio = drop_ratio).to(device) for _ in range(runs_per_split)])\n",
    "\n",
    "for split_id in range(1, total_splits + 1):\n",
    "    for run_id in range(1, runs_per_split + 1):\n",
    "        checkpoint_model = './2d_checkpoints/checkpoint_split{}_{}'.format(split_id, run_id)\n",
    "        checkpoint_path = os.path.join(checkpoint_model, 'checkpoint.pt')\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model_list[split_id - 1][run_id - 1].load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "num_params = sum(p.numel() for p in model_list[0][0].parameters())\n",
    "print(f'#Params: {num_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6855993",
   "metadata": {},
   "source": [
    "### 2D Model Validation Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3579c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 298/298 [00:26<00:00, 11.24it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.50it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.15it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.72it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:28<00:00, 10.45it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.73it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.55it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.59it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:29<00:00,  9.96it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.58it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.47it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.50it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:31<00:00,  9.59it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.27it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.46it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.59it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:30<00:00,  9.77it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.57it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.16it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.74it/s]\n"
     ]
    }
   ],
   "source": [
    "## get validation result for every run\n",
    "valid_pred_all = []\n",
    "y_true_list = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    valid_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        res_dict = eval(model_list[split_id][run_id], valid_loader)\n",
    "        valid_pred_split.append(res_dict[\"y_pred\"])\n",
    "        if run_id == 0:\n",
    "            y_true_list.append(res_dict[\"y_true\"])\n",
    "    valid_pred_all.append(valid_pred_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c9d90",
   "metadata": {},
   "source": [
    "### 2D Model Test Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "965db326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1475/1475 [02:27<00:00,  9.97it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:55<00:00, 12.78it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:52<00:00, 13.14it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:49<00:00, 13.49it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:16<00:00, 10.77it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:50<00:00, 13.39it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:48<00:00, 13.64it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:47<00:00, 13.70it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:17<00:00, 10.75it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:47<00:00, 13.72it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:48<00:00, 13.64it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.86it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:15<00:00, 10.91it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.79it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:48<00:00, 13.59it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.85it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:14<00:00, 10.97it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:48<00:00, 13.62it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred_all = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    test_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        y_pred = test_eval(model_list[split_id][run_id], test_loader)\n",
    "        test_pred_split.append(y_pred)\n",
    "    test_pred_all.append(test_pred_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d531bf5",
   "metadata": {},
   "source": [
    "## 3D Model Validation / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d50ad9",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c01e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer_root = 'dataset/kdd_confs_rms05_c40'\n",
    "all_dataset_val = ConfLmdbDataset(root=conformer_root, split='all', max_confs=40, training=False)\n",
    "missing_index = all_dataset_val.missing_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb0088",
   "metadata": {},
   "source": [
    "### Define and Load 3D Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c37a52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    cutoff = 5.0\n",
    "    num_gnn_layers = 5\n",
    "    hidden_dim = 600\n",
    "    num_filters = 300\n",
    "    use_conf = True\n",
    "    use_graph = True\n",
    "    num_tasks = 1\n",
    "    virtual_node = True\n",
    "    residual = True\n",
    "\n",
    "conformer_model_list = []\n",
    "\n",
    "for split_id in range(5):\n",
    "    conformer_model_split = []\n",
    "    # For each split, model is ensembled with checkpoints from five different epochs. \n",
    "    # The epochs are selected as the best validation epochs on the five respective splits,\n",
    "    # except for split 4 for which we select different epochs based on its validation results.\n",
    "    if split_id == 3:\n",
    "        epoch_list = [46, 50, 51, 52, 53]\n",
    "    else:\n",
    "        epoch_list = [45, 46, 48, 49, 53]\n",
    "    for epoch in epoch_list:\n",
    "        conformer_model = ConfNetDSS(config).to(device)\n",
    "        checkpoint = torch.load(f'conformer_checkpoints/checkpoint_{split_id+1}_{epoch}.pt', map_location=device)\n",
    "        conformer_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        conformer_model_split.append(conformer_model)\n",
    "    conformer_model_list.append(conformer_model_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a63a71",
   "metadata": {},
   "source": [
    "### 3D Model Validation Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed965b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.75it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:57<00:00,  5.20it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:06<00:00,  4.51it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:01<00:00,  4.85it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:04<00:00,  4.66it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.79it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.77it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:00<00:00,  4.96it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:06<00:00,  4.51it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:04<00:00,  4.64it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:57<00:00,  5.17it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:01<00:00,  4.87it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:00<00:00,  4.94it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:59<00:00,  4.99it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:59<00:00,  5.02it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:05<00:00,  4.54it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:06<00:00,  4.50it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:09<00:00,  4.29it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.78it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:05<00:00,  4.56it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:01<00:00,  4.85it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:06<00:00,  4.51it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.74it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:02<00:00,  4.79it/s]\n",
      "Iteration: 100%|██████████| 298/298 [01:04<00:00,  4.65it/s]\n"
     ]
    }
   ],
   "source": [
    "## get validation result for every selected epochs\n",
    "conformer_valid_pred_list = []\n",
    "for split_id in range(5):\n",
    "    with open(os.path.join(conformer_root, f'split_idx/valid_idx_{split_id+1}.pkl'), 'rb') as f:\n",
    "        valid_idx, valid_missing_index_position = pickle.load(f)\n",
    "    conformer_valid_dataset = torch.utils.data.Subset(all_dataset_val, valid_idx)\n",
    "    conformer_valid_loader = ConfDataLoader(conformer_valid_dataset, batch_size=256, shuffle=False, num_workers=4)        \n",
    " \n",
    "    y_pred_list = []\n",
    "    for conformer_model in conformer_model_list[split_id]:\n",
    "        y_pred = eval(conformer_model, conformer_valid_loader)['y_pred']\n",
    "        \n",
    "        # Add missing indices\n",
    "        y_pred = list(y_pred)\n",
    "        for i in valid_missing_index_position:\n",
    "            y_pred.insert(i, -1)\n",
    "            \n",
    "        y_pred = torch.Tensor(y_pred)\n",
    "        y_pred_list.append(y_pred)\n",
    "        \n",
    "    # Average predictions from different epochs\n",
    "    y_pred = torch.mean(torch.stack(y_pred_list, dim=0), dim=0)\n",
    "    conformer_valid_pred_list.append(y_pred)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb5a6e6",
   "metadata": {},
   "source": [
    "### 3D Model Test Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712f7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a little bit too long to run in a notebook.\n",
    "# Please run `python conformer_test.py` to get the test results.\n",
    "conformer_test_pred_list = []\n",
    "for split_id in range(total_splits):\n",
    "    conformer_test_pred_list.append(np.load(f'test_result/conformer_test_{split_id+1}/y_pred_pcqm4m.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88662bc",
   "metadata": {},
   "source": [
    "## 2D & 3D Ensemble Validation / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1579456",
   "metadata": {},
   "source": [
    "### Final Validation Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512cd7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on validation set: 0.11165784299373627\n",
      "MAE on validation set: 0.11134495586156845\n",
      "MAE on validation set: 0.11199122667312622\n",
      "MAE on validation set: 0.11113344877958298\n",
      "MAE on validation set: 0.11137096583843231\n"
     ]
    }
   ],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_res_split = []\n",
    "for i in range(total_splits):\n",
    "    valid_pred = torch.mean(torch.stack(valid_pred_all[i]), axis=0)\n",
    "    valid_pred_final = (valid_pred.numpy() + w * conformer_valid_pred_list[i].numpy()) / (1 + w)\n",
    "    idx = (conformer_valid_pred_list[i] == -1)\n",
    "    valid_pred_final[idx] = valid_pred[idx]\n",
    "    ensemble_res_split.append(valid_pred_final)\n",
    "\n",
    "for i in range(len(ensemble_res_split)):\n",
    "    input_dict = {\"y_true\": y_true_list[i].numpy(), \"y_pred\": ensemble_res_split[i]}\n",
    "    print('MAE on validation set:', evaluator.eval(input_dict)[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5321e9a",
   "metadata": {},
   "source": [
    "### Final Test Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_test_res_split = []\n",
    "for i in range(total_splits):\n",
    "    test_pred = torch.mean(torch.stack(test_pred_all[i]), axis=0)\n",
    "    test_pred_final = (test_pred.numpy() + w * conformer_test_pred_list[i]['y_pred']) / (1 + w)\n",
    "    idx = (conformer_test_pred_list[i]['y_pred'] == -1)\n",
    "    test_pred_final[idx] = test_pred[idx]\n",
    "    ensemble_test_res_split.append(test_pred_final)\n",
    "\n",
    "## ensemble over all splits\n",
    "save_test_dir = './test_result'\n",
    "y_pred = np.mean(np.array(ensemble_test_res_split), axis=0)\n",
    "evaluator.save_test_submission({'y_pred': y_pred}, save_test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
