{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef3bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The OGB package is out of date. Your version is 1.3.0, while the latest version is 1.3.1.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from ogb.lsc import PygPCQM4MDataset, PCQM4MEvaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from deeper_dagnn import DeeperDAGNN_node_Virtualnode\n",
    "from conformer.dataset import ConfLmdbDataset, ConfDataLoader\n",
    "from conformer.confnet_dss import ConfNetDSS\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8110a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935cd4cb",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991de6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygPCQM4MDataset()\n",
    "evaluator = PCQM4MEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307d8c7",
   "metadata": {},
   "source": [
    "### Define and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "602581c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 34093834\n"
     ]
    }
   ],
   "source": [
    "num_layers = 16\n",
    "emb_dim = 600\n",
    "drop_ratio = 0.25\n",
    "\n",
    "total_splits = 5\n",
    "runs_per_split = 4\n",
    "model_list = []\n",
    "for _ in range(total_splits):\n",
    "    model_list.append([DeeperDAGNN_node_Virtualnode(num_layers=num_layers, emb_dim=emb_dim, drop_ratio = drop_ratio).to(device) for _ in range(runs_per_split)])\n",
    "\n",
    "for split_id in range(1, total_splits + 1):\n",
    "    for run_id in range(1, runs_per_split + 1):\n",
    "        checkpoint_model = './2d_checkpoints/checkpoint_split{}_{}'.format(split_id, run_id)\n",
    "        checkpoint_path = os.path.join(checkpoint_model, 'checkpoint.pt')\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model_list[split_id - 1][run_id - 1].load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "num_params = sum(p.numel() for p in model_list[0][0].parameters())\n",
    "print(f'#Params: {num_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb4ad8",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aaefc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, valid_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for step, batch in enumerate(tqdm(valid_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0)\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "\n",
    "    res_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6855993",
   "metadata": {},
   "source": [
    "### Validation Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3579c0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 298/298 [00:27<00:00, 10.89it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.32it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.60it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.94it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:31<00:00,  9.56it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.39it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.43it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.37it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:28<00:00, 10.30it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:22<00:00, 13.46it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.34it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 13.56it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:27<00:00, 10.96it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.35it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.62it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:21<00:00, 14.16it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:27<00:00, 10.65it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.54it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.53it/s]\n",
      "Iteration: 100%|██████████| 298/298 [00:20<00:00, 14.56it/s]\n"
     ]
    }
   ],
   "source": [
    "## get validation result for every run\n",
    "valid_pred_all = []\n",
    "y_true_list = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    valid_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        res_dict = eval(model_list[split_id][run_id], valid_loader)\n",
    "        valid_pred_split.append(res_dict[\"y_pred\"])\n",
    "        if run_id == 0:\n",
    "            y_true_list.append(res_dict[\"y_true\"])\n",
    "    valid_pred_all.append(valid_pred_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c37a52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation result of conformer\n",
    "# 3D model\n",
    "class config:\n",
    "    cutoff = 5.0\n",
    "    num_gnn_layers = 5\n",
    "    hidden_dim = 600\n",
    "    num_filters = 300\n",
    "    use_conf = True\n",
    "    use_graph = True\n",
    "    num_tasks = 1\n",
    "    virtual_node = True\n",
    "    residual = True\n",
    "conformer_model = ConfNetDSS(config).to(device)\n",
    "\n",
    "conformer_root = 'dataset/kdd_confs_rms05_c40'\n",
    "\n",
    "conformer_valid_pred_list = []\n",
    "for split_id in [1, 2, 3, 4, 5]:\n",
    "    print('split', split_id)\n",
    "    all_dataset_val = ConfLmdbDataset(root=conformer_root, split='all', max_confs=40, training=False)\n",
    "    missing_index = all_dataset_val.missing_index\n",
    "\n",
    "    with open(os.path.join(conformer_root, f'split_idx/valid_idx_{split_id}.pkl'), 'rb') as f:\n",
    "        valid_idx, valid_missing_index_position = pickle.load(f)\n",
    "   \n",
    "    conformer_valid_dataset = torch.utils.data.Subset(all_dataset_val, valid_idx)\n",
    "    conformer_valid_loader = ConfDataLoader(conformer_valid_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # For each split, ensemble with models from 5 different epochs\n",
    "    if split_id == 4:\n",
    "        epoch_list = [46, 50, 51, 52, 53]\n",
    "    else:\n",
    "        epoch_list = [45, 46, 48, 49, 53]\n",
    "        \n",
    " \n",
    "    y_pred_list = []\n",
    "    for epoch in epoch_list:\n",
    "        checkpoint = torch.load(f'conformer_checkpoints/checkpoint_{split_id}_{epoch}.pt', map_location=device)\n",
    "        conformer_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        y_pred = eval(conformer_model, conformer_valid_loader)['y_pred']\n",
    "        \n",
    "        # Add missing indices\n",
    "        y_pred = list(y_pred)\n",
    "        for i in valid_missing_index_position:\n",
    "            y_pred.insert(i, -1)\n",
    "            \n",
    "        y_pred = torch.Tensor(y_pred)\n",
    "        y_pred_list.append(y_pred)\n",
    "        \n",
    "    # Average predictions from different epochs\n",
    "    y_pred = torch.mean(torch.stack(y_pred_list, dim=0), dim=0)\n",
    "    conformer_valid_pred_list.append(y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "512cd7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on validation set: 0.11165887862443924\n",
      "MAE on validation set: 0.11134455353021622\n",
      "MAE on validation set: 0.11199045181274414\n",
      "MAE on validation set: 0.11113350093364716\n",
      "MAE on validation set: 0.11137155443429947\n"
     ]
    }
   ],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_res_split = []\n",
    "for i in range(total_splits):\n",
    "    valid_pred = torch.mean(torch.stack(valid_pred_all[i]), axis=0)\n",
    "    valid_pred_final = (valid_pred.numpy() + w * conformer_valid_pred_list[i]['y_pred']) / (1 + w)\n",
    "    idx = (conformer_valid_pred_list[i]['y_pred'] == -1)\n",
    "    valid_pred_final[idx] = valid_pred[idx]\n",
    "    ensemble_res_split.append(valid_pred_final)\n",
    "\n",
    "for i in range(len(ensemble_res_split)):\n",
    "    input_dict = {\"y_true\": y_true_list[i].numpy(), \"y_pred\": ensemble_res_split[i]}\n",
    "    print('MAE on validation set:', evaluator.eval(input_dict)[\"mae\"])\n",
    "## ensemble over all splits\n",
    "# y_pred = np.mean(np.array(ensemble_res_split), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8afdf5d",
   "metadata": {},
   "source": [
    "### Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f38470ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, test_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    for step, batch in enumerate(tqdm(test_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch).view(-1,)\n",
    "\n",
    "        y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_pred = torch.cat(y_pred, dim = 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811d5b9",
   "metadata": {},
   "source": [
    "### Test Result Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a4878f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 1475/1475 [02:33<00:00,  9.63it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:53<00:00, 13.00it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:47<00:00, 13.70it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.80it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:15<00:00, 10.90it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.83it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:14<00:00, 10.98it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.81it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:48<00:00, 13.62it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:47<00:00, 13.78it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:14<00:00, 10.95it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.84it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.83it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.83it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [02:15<00:00, 10.91it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.84it/s]\n",
      "Iteration: 100%|██████████| 1475/1475 [01:46<00:00, 13.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test_pred_all = []\n",
    "for split_id in range(total_splits):\n",
    "    split_idx = torch.load('./split_idx/new_split{}.pt'.format(split_id+1))\n",
    "    test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=256, shuffle=False, num_workers = 0)\n",
    "    test_pred_split = []\n",
    "    for run_id in range(runs_per_split):\n",
    "        y_pred = test_eval(model_list[split_id][run_id], test_loader)\n",
    "        test_pred_split.append(y_pred)\n",
    "    test_pred_all.append(test_pred_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32ad306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test result of conformer\n",
    "# 3D model\n",
    "class config:\n",
    "    cutoff = 5.0\n",
    "    num_gnn_layers = 5\n",
    "    hidden_dim = 600\n",
    "    num_filters = 300\n",
    "    use_conf = True\n",
    "    use_graph = True\n",
    "    num_tasks = 1\n",
    "    virtual_node = True\n",
    "    residual = True\n",
    "conformer_model = ConfNetDSS(config).to(device)\n",
    "\n",
    "conformer_root = 'dataset/kdd_confs_rms05_c40'\n",
    "\n",
    "conformer_test_pred_list = []\n",
    "for split_id in [1, 2, 3, 4, 5]:\n",
    "    print('split', split_id)\n",
    "    all_dataset_val = ConfLmdbDataset(root=conformer_root, split='all', max_confs=40, training=False)\n",
    "    missing_index = all_dataset_val.missing_index\n",
    "\n",
    "    with open(os.path.join(conformer_root, f'split_idx/test_idx_{split_id}.pkl'), 'rb') as f:\n",
    "        test_idx, test_missing_index_position = pickle.load(f)\n",
    "   \n",
    "    conformer_test_dataset = torch.utils.data.Subset(all_dataset_val, test_idx)\n",
    "    conformer_test_loader = ConfDataLoader(conformer_test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # For each split, ensemble with models from 5 different epochs\n",
    "    if split_id == 4:\n",
    "        epoch_list = [46, 50, 51, 52, 53]\n",
    "    else:\n",
    "        epoch_list = [45, 46, 48, 49, 53]\n",
    "    \n",
    "    y_pred_list = []\n",
    "    for epoch in epoch_list:\n",
    "        checkpoint = torch.load(f'conformer_checkpoints/checkpoint_{split_id}_{epoch}.pt', map_location=device)\n",
    "        conformer_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        y_pred = test_eval(conformer_model, conformer_test_loader)\n",
    "        \n",
    "        # Add missing indices\n",
    "        y_pred = list(y_pred)\n",
    "        for i in test_missing_index_position:\n",
    "            y_pred.insert(i, -1)\n",
    "            \n",
    "        y_pred = torch.Tensor(y_pred)\n",
    "        y_pred_list.append(y_pred)\n",
    "    \n",
    "    # Average predictions from different epochs\n",
    "    y_pred = torch.mean(torch.stack(y_pred_list, dim=0), dim=0)\n",
    "    conformer_test_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2407d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensemble for every split\n",
    "w = 0.27\n",
    "ensemble_test_res_split = []\n",
    "for i in range(total_splits):\n",
    "    test_pred = torch.mean(torch.stack(test_pred_all[i]), axis=0)\n",
    "    test_pred_final = (test_pred.numpy() + w * conformer_test_pred_list[i]['y_pred']) / (1 + w)\n",
    "    idx = (conformer_test_pred_list[i]['y_pred'] == -1)\n",
    "    test_pred_final[idx] = test_pred[idx]\n",
    "    ensemble_test_res_split.append(test_pred_final)\n",
    " \n",
    "## ensemble over all splits\n",
    "save_test_dir = './test_result'\n",
    "y_pred = np.mean(np.array(ensemble_test_res_split), axis=0)\n",
    "evaluator.save_test_submission({'y_pred': y_pred}, save_test_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
